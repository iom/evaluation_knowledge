<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.39">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Workflow Description – evaluation_knowledge</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e26003cea8cd680ca0c55a263523d882.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-fad5ab29a14bbe0a7a7d29177f3f13bb.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="Workflow Description – evaluation_knowledge">
<meta property="og:description" content="A module to turn Evaluation Reports into AI knowledge">
<meta property="og:site_name" content="evaluation_knowledge">
<meta name="twitter:title" content="Workflow Description – evaluation_knowledge">
<meta name="twitter:description" content="A module to turn Evaluation Reports into AI knowledge">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">evaluation_knowledge</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./core.html">Workflow Description</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">AI-Assisted Evaluation Evidence Mapping</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Workflow Description</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a>
  <ul class="collapse">
  <li><a href="#create-a-virtual-environment" id="toc-create-a-virtual-environment" class="nav-link" data-scroll-target="#create-a-virtual-environment">Create a Virtual Environment</a></li>
  <li><a href="#required-python-modules" id="toc-required-python-modules" class="nav-link" data-scroll-target="#required-python-modules">Required Python Modules</a></li>
  <li><a href="#initialise-llm-api" id="toc-initialise-llm-api" class="nav-link" data-scroll-target="#initialise-llm-api">Initialise LLM API</a></li>
  <li><a href="#load-pdf-library-and-strategic-results-framework" id="toc-load-pdf-library-and-strategic-results-framework" class="nav-link" data-scroll-target="#load-pdf-library-and-strategic-results-framework">Load PDF library and Strategic Results Framework</a></li>
  <li><a href="#load_evaluations" id="toc-load_evaluations" class="nav-link" data-scroll-target="#load_evaluations">load_evaluations</a></li>
  <li><a href="#load_iom_framework" id="toc-load_iom_framework" class="nav-link" data-scroll-target="#load_iom_framework">load_iom_framework</a></li>
  </ul></li>
  <li><a href="#step-1-building-the-knowledge-base" id="toc-step-1-building-the-knowledge-base" class="nav-link" data-scroll-target="#step-1-building-the-knowledge-base">Step 1: Building the Knowledge Base</a>
  <ul class="collapse">
  <li><a href="#initialize-lancedb-vector-database" id="toc-initialize-lancedb-vector-database" class="nav-link" data-scroll-target="#initialize-lancedb-vector-database">Initialize LanceDB Vector Database</a></li>
  <li><a href="#load_evaluations-1" id="toc-load_evaluations-1" class="nav-link" data-scroll-target="#load_evaluations-1">load_evaluations</a></li>
  <li><a href="#generate_id" id="toc-generate_id" class="nav-link" data-scroll-target="#generate_id">generate_id</a></li>
  <li><a href="#force_delete_directory" id="toc-force_delete_directory" class="nav-link" data-scroll-target="#force_delete_directory">force_delete_directory</a></li>
  <li><a href="#initialise_knowledge_base" id="toc-initialise_knowledge_base" class="nav-link" data-scroll-target="#initialise_knowledge_base">initialise_knowledge_base</a></li>
  <li><a href="#safe_get" id="toc-safe_get" class="nav-link" data-scroll-target="#safe_get">safe_get</a></li>
  <li><a href="#download-and-prepare-all-the-files" id="toc-download-and-prepare-all-the-files" class="nav-link" data-scroll-target="#download-and-prepare-all-the-files">Download and prepare all the files</a></li>
  <li><a href="#download_documents" id="toc-download_documents" class="nav-link" data-scroll-target="#download_documents">download_documents</a></li>
  <li><a href="#convert_file_to_pdf" id="toc-convert_file_to_pdf" class="nav-link" data-scroll-target="#convert_file_to_pdf">convert_file_to_pdf</a></li>
  <li><a href="#find_libreoffice_exec" id="toc-find_libreoffice_exec" class="nav-link" data-scroll-target="#find_libreoffice_exec">find_libreoffice_exec</a></li>
  <li><a href="#now-load-file-content-in-the-vector-db-chunk-and-embedd" id="toc-now-load-file-content-in-the-vector-db-chunk-and-embedd" class="nav-link" data-scroll-target="#now-load-file-content-in-the-vector-db-chunk-and-embedd">Now load file content in the vector DB, chunk and embedd</a></li>
  <li><a href="#process_documents_to_chunks" id="toc-process_documents_to_chunks" class="nav-link" data-scroll-target="#process_documents_to_chunks">process_documents_to_chunks</a></li>
  <li><a href="#check_chunk_status" id="toc-check_chunk_status" class="nav-link" data-scroll-target="#check_chunk_status">check_chunk_status</a></li>
  <li><a href="#generating-ai-enhanced-metadata" id="toc-generating-ai-enhanced-metadata" class="nav-link" data-scroll-target="#generating-ai-enhanced-metadata">Generating AI-Enhanced metadata</a></li>
  <li><a href="#get_context_for_eval" id="toc-get_context_for_eval" class="nav-link" data-scroll-target="#get_context_for_eval">get_context_for_eval</a></li>
  <li><a href="#call_llm_with_retries" id="toc-call_llm_with_retries" class="nav-link" data-scroll-target="#call_llm_with_retries">call_llm_with_retries</a></li>
  <li><a href="#safe_join" id="toc-safe_join" class="nav-link" data-scroll-target="#safe_join">safe_join</a></li>
  <li><a href="#clean_json" id="toc-clean_json" class="nav-link" data-scroll-target="#clean_json">clean_json</a></li>
  <li><a href="#generate_metadata_for_evaluation_metadata_descriptive" id="toc-generate_metadata_for_evaluation_metadata_descriptive" class="nav-link" data-scroll-target="#generate_metadata_for_evaluation_metadata_descriptive">generate_metadata_for_evaluation_metadata_descriptive</a></li>
  <li><a href="#generate_metadata_for_evaluation_metadata_methodo" id="toc-generate_metadata_for_evaluation_metadata_methodo" class="nav-link" data-scroll-target="#generate_metadata_for_evaluation_metadata_methodo">generate_metadata_for_evaluation_metadata_methodo</a></li>
  <li><a href="#generate_metadata_for_evaluation_metadata_evidence" id="toc-generate_metadata_for_evaluation_metadata_evidence" class="nav-link" data-scroll-target="#generate_metadata_for_evaluation_metadata_evidence">generate_metadata_for_evaluation_metadata_evidence</a></li>
  <li><a href="#generate_evaluation_metadata" id="toc-generate_evaluation_metadata" class="nav-link" data-scroll-target="#generate_evaluation_metadata">generate_evaluation_metadata</a></li>
  </ul></li>
  <li><a href="#step-2-structured-information-extraction" id="toc-step-2-structured-information-extraction" class="nav-link" data-scroll-target="#step-2-structured-information-extraction">Step 2: Structured Information Extraction</a>
  <ul class="collapse">
  <li><a href="#standard-questions" id="toc-standard-questions" class="nav-link" data-scroll-target="#standard-questions">Standard Questions</a></li>
  <li><a href="#qa-extraction" id="toc-qa-extraction" class="nav-link" data-scroll-target="#qa-extraction">Q&amp;A Extraction</a></li>
  <li><a href="#hybrid-search-in-lancedb" id="toc-hybrid-search-in-lancedb" class="nav-link" data-scroll-target="#hybrid-search-in-lancedb">Hybrid Search in LanceDB</a></li>
  </ul></li>
  <li><a href="#step-3-cross-evaluation-analysis" id="toc-step-3-cross-evaluation-analysis" class="nav-link" data-scroll-target="#step-3-cross-evaluation-analysis">Step 3: Cross-Evaluation Analysis</a></li>
  <li><a href="#step-4-generate-actionable-and-generalizable-insights" id="toc-step-4-generate-actionable-and-generalizable-insights" class="nav-link" data-scroll-target="#step-4-generate-actionable-and-generalizable-insights">Step 4: Generate Actionable and Generalizable Insights</a></li>
  <li><a href="#step-5-identify-patterns-and-gaps" id="toc-step-5-identify-patterns-and-gaps" class="nav-link" data-scroll-target="#step-5-identify-patterns-and-gaps">Step 5: Identify Patterns and Gaps</a></li>
  <li><a href="#conclusions---and-potential-extension" id="toc-conclusions---and-potential-extension" class="nav-link" data-scroll-target="#conclusions---and-potential-extension">Conclusions - and potential extension…</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/iom/evaluation_knowledge/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div><div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="core.html.md"><i class="bi bi-file-code"></i>CommonMark</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Workflow Description</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>This notebook implements an evidence mapping system with:</p>
<ul>
<li><p>Batch processing for scalability</p></li>
<li><p>Robust error handling and retries</p></li>
<li><p>Embedding caching</p></li>
<li><p>Hybrid search (vector + full-text)</p></li>
<li><p>Local LanceDB deployment</p></li>
</ul>
<p>we can follow these steps:</p>
<ul>
<li>Load the JSON file containing the URLs of the PDF reports.</li>
<li>Load the Excel file describing the IOM Results Framework.</li>
<li>Download and process the PDF reports to extract text.</li>
<li>Integrate the extracted text with the IOM Results Framework.</li>
<li>Generate embeddings and store them in LanceDB.</li>
</ul>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<section id="create-a-virtual-environment" class="level3">
<h3 class="anchored" data-anchor-id="create-a-virtual-environment">Create a Virtual Environment</h3>
<p>To ensure a clean and isolated environment for this project, we will create a virtual environment using Python’s <code>venv</code> module. This will help manage dependencies and avoid conflicts with other projects.</p>
<pre class="{bash}"><code>#| eval: false
python -m venv .venv</code></pre>
<p>Then, activate the virtual environment:</p>
<pre class="{bash}"><code>#| eval: false
.\.venv\Scripts\activate</code></pre>
<p>Then, configure visual Studio Code to use the virtual environment: Open the Command Palette using the shortcut <code>Ctrl+Shift+P</code> and type <code>Jupyter: Select Interpreter</code> and select the interpreter that corresponds to your newly created virtual environment: <code>('venv': venv)</code>.</p>
</section>
<section id="required-python-modules" class="level3">
<h3 class="anchored" data-anchor-id="required-python-modules">Required Python Modules</h3>
<p>Once this environment selected as a kernel to run the notebook, we can install the required python modules the rest of the process:</p>
<pre class="{python}"><code>%pip install openai  lancedb pyarrow pandas numpy matplotlib seaborn plotly pymupdf requests tqdm tenacity ipython dotenv langchain langchain-community langchain_openai  ipywidgets openpyxl  filetype</code></pre>
<p>then Restart the jupyter kernel for this notebook</p>
<pre class="{python}"><code>#| eval: false
%reset -f</code></pre>
</section>
<section id="initialise-llm-api" class="level3">
<h3 class="anchored" data-anchor-id="initialise-llm-api">Initialise LLM API</h3>
<div id="llmapi" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load environment variables</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>load_dotenv()</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain_openai <span class="im">import</span> AzureChatOpenAI </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize LLM with higher temperature for creative question generation</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>llm_creative <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    deployment_name<span class="op">=</span>os.getenv(<span class="st">"AZURE_DEPLOYMENT_NAME"</span>),</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    api_key<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_API_KEY"</span>),</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    azure_endpoint<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_ENDPOINT"</span>),</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    api_version<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_API_VERSION"</span>),</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">500</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>llm_accurate <span class="op">=</span> AzureChatOpenAI(</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    deployment_name<span class="op">=</span>os.getenv(<span class="st">"AZURE_DEPLOYMENT_NAME"</span>),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    api_key<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_API_KEY"</span>),</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    azure_endpoint<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_ENDPOINT"</span>),</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    api_version<span class="op">=</span>os.getenv(<span class="st">"AZURE_OPENAI_API_VERSION"</span>),</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.1</span>,</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">1000</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-pdf-library-and-strategic-results-framework" class="level3">
<h3 class="anchored" data-anchor-id="load-pdf-library-and-strategic-results-framework">Load PDF library and Strategic Results Framework</h3>
<p>The library</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L104" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="load_evaluations" class="level3">
<h3 class="anchored" data-anchor-id="load_evaluations">load_evaluations</h3>
<blockquote class="blockquote">
<pre><code> load_evaluations (file_path, json_path)</code></pre>
</blockquote>
<div id="cell-7" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>library <span class="op">=</span>load_evaluations(<span class="st">"reference/Evaluation_repository.xlsx"</span>,<span class="st">"reference/Evaluation_repository.json"</span> )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now the framework</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L88" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="load_iom_framework" class="level3">
<h3 class="anchored" data-anchor-id="load_iom_framework">load_iom_framework</h3>
<blockquote class="blockquote">
<pre><code> load_iom_framework (excel_path:str)</code></pre>
</blockquote>
<p><em>Load and validate IOM framework</em></p>
<div id="cell-10" class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>framework<span class="op">=</span> load_iom_framework(<span class="st">"reference/Strategic_Result_Framework.xlsx"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="step-1-building-the-knowledge-base" class="level2">
<h2 class="anchored" data-anchor-id="step-1-building-the-knowledge-base">Step 1: Building the Knowledge Base</h2>
<p>So we have a collection of Evaluation documents. We have metadata for each Evaluation. For each evaluation, we have multiple documents (The evaluation report itslef, plus in some case: a summary brief, annexes, etc.)</p>
<p>See an example below</p>
<div id="cell-12" class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>[</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Title"</span>: <span class="st">"Finale Internal Evluation: ENHANCING THE CAPACITY TO MAINSTREAM ENVIRONMENT AND CLIMATE CHANGE WITHIN WIDER FRAMEWORK OF MIGRATION MANAGEMENT IN WEST AND CENTRAL AFRICA"</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Year"</span>: <span class="st">"2022"</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Author"</span>: <span class="st">"Abderrahim El Moulat"</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Best Practices or Lessons Learnt"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Date of Publication"</span>: <span class="st">"2022-06-22 00:00:00"</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Donor"</span>: <span class="st">"IOM Development Fund"</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Brief"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Commissioner"</span>: <span class="st">"Donor, IOM"</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Coverage"</span>: <span class="st">"Country"</span>,</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Period From Date"</span>: <span class="st">"nan"</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Period To Date"</span>: <span class="st">"NaT"</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Executive Summary"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"External Version of the Report"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Languages"</span>: <span class="st">"English"</span>,</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Migration Thematic Areas"</span>: <span class="st">"Migration and climate change"</span>,</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Name of Project(s) Being Evaluated"</span>: NaN,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Number of Pages Excluding annexes"</span>: <span class="fl">20.0</span>,</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Other Documents Included"</span>: NaN,</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Project Code"</span>: <span class="st">"NC.0030"</span>,</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Countries Covered"</span>: [</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Senegal"</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Regions Covered"</span>: <span class="st">"RO Dakar"</span>,</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Relevant Crosscutting Themes"</span>: <span class="st">"Gender"</span>,</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Report Published"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Terms of Reference"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluation Scope"</span>: <span class="st">"Programme/Project"</span>,</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluation Timing"</span>: <span class="st">"Ex-post (after the end of the project/programme)"</span>,</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluator"</span>: <span class="st">"Internal"</span>,</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Level of Evaluation"</span>: <span class="st">"Decentralized"</span>,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Documents"</span>: [</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Document Subtype"</span>: <span class="st">"Evaluation brief"</span>,</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File URL"</span>: <span class="st">"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Internal</span><span class="sc">%20E</span><span class="st">valuation_NC0030_JUNE_2022_FINAL_Abderrahim</span><span class="sc">%20E</span><span class="st">L%20MOULAT_0.pdf"</span>,</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File description"</span>: <span class="st">"Evaluation Brief"</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Document Subtype"</span>: <span class="st">"Evaluation report"</span>,</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File URL"</span>: <span class="st">"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/NC0030_Evaluation%20Brief_June%202022_Abderrahim</span><span class="sc">%20E</span><span class="st">L%20MOULAT.pdf"</span>,</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File description"</span>: <span class="st">"Evaluation Report"</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Title"</span>: <span class="st">"Local Authorities Network for Migration and Development"</span>,</span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Year"</span>: <span class="st">"2022"</span>,</span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Author"</span>: <span class="st">"Action Research for CO-development (ARCO)"</span>,</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Best Practices or Lessons Learnt"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Date of Publication"</span>: <span class="st">"2022-02-01 00:00:00"</span>,</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Donor"</span>: <span class="st">"Government of Italy"</span>,</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Brief"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Commissioner"</span>: <span class="st">"IOM"</span>,</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Coverage"</span>: <span class="st">"Multi-country"</span>,</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Period From Date"</span>: <span class="st">"2020-07-06 00:00:00"</span>,</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Evaluation Period To Date"</span>: <span class="st">"2021-07-31 00:00:00"</span>,</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Executive Summary"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">"External Version of the Report"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Languages"</span>: <span class="st">"English"</span>,</span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Migration Thematic Areas"</span>: <span class="st">"Migration and Development - diaspora"</span>,</span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Name of Project(s) Being Evaluated"</span>: NaN,</span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Number of Pages Excluding annexes"</span>: <span class="fl">37.0</span>,</span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Other Documents Included"</span>: NaN,</span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Project Code"</span>: <span class="st">"MD.0003"</span>,</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Countries Covered"</span>: [</span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Albania"</span>,</span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>            <span class="st">"Italy"</span></span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Regions Covered"</span>: <span class="st">"RO Brussels"</span>,</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Relevant Crosscutting Themes"</span>: <span class="st">"Gender, Rights-based approach"</span>,</span>
<span id="cb10-72"><a href="#cb10-72" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Report Published"</span>: <span class="st">"No"</span>,</span>
<span id="cb10-73"><a href="#cb10-73" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Terms of Reference"</span>: <span class="st">"Yes"</span>,</span>
<span id="cb10-74"><a href="#cb10-74" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluation Scope"</span>: <span class="st">"Programme/Project"</span>,</span>
<span id="cb10-75"><a href="#cb10-75" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluation Timing"</span>: <span class="st">"Final (at the end of the project/programme)"</span>,</span>
<span id="cb10-76"><a href="#cb10-76" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Type of Evaluator"</span>: <span class="st">"External"</span>,</span>
<span id="cb10-77"><a href="#cb10-77" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Level of Evaluation"</span>: <span class="st">"Decentralized"</span>,</span>
<span id="cb10-78"><a href="#cb10-78" aria-hidden="true" tabindex="-1"></a>        <span class="st">"Documents"</span>: [</span>
<span id="cb10-79"><a href="#cb10-79" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb10-80"><a href="#cb10-80" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Document Subtype"</span>: <span class="st">"Evaluation report"</span>,</span>
<span id="cb10-81"><a href="#cb10-81" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File URL"</span>: <span class="st">"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Evaluation%20Brief_ARCO_Shiraz%20JERBI.pdF"</span>,</span>
<span id="cb10-82"><a href="#cb10-82" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File description"</span>: <span class="st">"Evaluation Report "</span></span>
<span id="cb10-83"><a href="#cb10-83" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb10-84"><a href="#cb10-84" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb10-85"><a href="#cb10-85" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Document Subtype"</span>: <span class="st">"Evaluation brief"</span>,</span>
<span id="cb10-86"><a href="#cb10-86" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File URL"</span>: <span class="st">"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Final</span><span class="sc">%20e</span><span class="st">valuation</span><span class="sc">%20r</span><span class="st">eport_ARCO_Shiraz%20JERBI_1.pdf"</span>,</span>
<span id="cb10-87"><a href="#cb10-87" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File description"</span>: <span class="st">"Evaluation Brief"</span></span>
<span id="cb10-88"><a href="#cb10-88" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb10-89"><a href="#cb10-89" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb10-90"><a href="#cb10-90" aria-hidden="true" tabindex="-1"></a>                <span class="st">"Document Subtype"</span>: <span class="st">"Management response"</span>,</span>
<span id="cb10-91"><a href="#cb10-91" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File URL"</span>: <span class="st">"https://evaluation.iom.int/sites/g/files/tmzbdl151/files/docs/resources/Management%20Response%20Matrix_ARCO_Shiraz%20JERBI.pdf"</span>,</span>
<span id="cb10-92"><a href="#cb10-92" aria-hidden="true" tabindex="-1"></a>                <span class="st">"File description"</span>: <span class="st">"Management Response"</span></span>
<span id="cb10-93"><a href="#cb10-93" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb10-94"><a href="#cb10-94" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb10-95"><a href="#cb10-95" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb10-96"><a href="#cb10-96" aria-hidden="true" tabindex="-1"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Workflow Overview</p>
<ol type="1">
<li>Load external metadata for one evaluations as per json file.</li>
<li>Then for each evaluation, download the file, convert it to PDF (in case it’s a word, excel or ppt), and load text for each document.</li>
<li>Then implement a <a href="https://isaacflath.com/blog/blog_post?fpath=posts%2F2025-04-08-LateChunking.ipynb">late chunking that can solve the lost context problem</a> and insert in chunk table, enabling <a href="https://docs.lancedb.com/core/hybrid-search">Hybrid Search capability</a> so that search can be made based on both key words and similirarity.</li>
<li>Create additional metadata for both documents and for evaluation using an LLM call. the additional metadata shall help to define an asesssment of the “evidence strenght”. The metadata to be created are - evaluation type (formative, summative, impact), Methodology, study design, sample size, and data collection techniques</li>
</ol>
<section id="initialize-lancedb-vector-database" class="level3">
<h3 class="anchored" data-anchor-id="initialize-lancedb-vector-database">Initialize LanceDB Vector Database</h3>
<p>The database includes 23 tables:</p>
<p><strong>1. Evaluations Table</strong> Each row represents a unique evaluation with the following fields:</p>
<ul>
<li>evaluation_id (unique identifier)</li>
<li>title</li>
<li>author</li>
<li>practice_or_lessons</li>
<li>donor</li>
<li>is_brief</li>
<li>commissioner</li>
<li>coverage</li>
<li>countries</li>
<li>from_date</li>
<li>to_date</li>
<li>has_summary</li>
<li>external_version</li>
<li>language</li>
<li>thematic_area</li>
<li>name_project</li>
<li>project_code</li>
<li>evaluation_scope</li>
<li>evaluation_timing</li>
<li>evaluation_level</li>
<li>evaluator_type</li>
<li>theme</li>
<li>cross_cutting</li>
</ul>
<p>additional variable will be generated through an LLM prompt on the entire evaluation content</p>
<ul>
<li>short_title</li>
<li>summary</li>
<li>population (PICO model)</li>
<li>intervention (PICO model)</li>
<li>comparator (PICO model)</li>
<li>outcome (PICO model)</li>
<li>methodology</li>
<li>study_type</li>
<li>study_design</li>
<li>sample_size</li>
<li>data_collection_techniques</li>
<li>evidence_strength</li>
<li>limitations</li>
</ul>
<p><strong>2. Documents Table</strong></p>
<p>Each row represents a PDF file linked to an evaluation:</p>
<ul>
<li>document_id: Primary key ID of the original PDF</li>
<li>evaluation_id: foreign key to link to the evaluation</li>
<li>document_subtype: from the original metadata</li>
<li>document_url: from the original metadata</li>
<li>document_name: from the original metadata</li>
<li>document_tite: document type as reviewed by the LLM</li>
<li>document_type_infer: document type as reviewed by the LLM</li>
<li>document_processed: boolean to confirm it is done</li>
</ul>
<p><strong>3. Chunk Table</strong> * chunk_id: Primary key<br>
* evaluation_id: foreign key to link to the evaluation * document_id: ID of the original file * document_page: for proper referencing of any further information retrieval * chunk_index: order of the chunk in the document * text: the chunked content * embedding (for hybrid search)</p>
<p>Let’s start by loading the library from json…</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L104" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="load_evaluations-1" class="level3">
<h3 class="anchored" data-anchor-id="load_evaluations-1">load_evaluations</h3>
<blockquote class="blockquote">
<pre><code> load_evaluations (json_path:str)</code></pre>
</blockquote>
<p>*Load evaluation data from a JSON file</p>
<p>Args: json_path: Path to the JSON file containing evaluation data</p>
<p>Returns: List of evaluation dictionaries*</p>
<p>Load a small subset for testing..</p>
<div id="cell-17" class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load your   metadata</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#evaluation_data =  load_evaluations("reference/Evaluation_repository_test.json")</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>evaluation_data <span class="op">=</span>  load_evaluations(<span class="st">"reference/Evaluation_repository.json"</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Attribute name is: </span><span class="sc">{</span>evaluation_data<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(evaluation_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Id Generation</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L136" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="generate_id" class="level3">
<h3 class="anchored" data-anchor-id="generate_id">generate_id</h3>
<blockquote class="blockquote">
<pre><code> generate_id (text:str)</code></pre>
</blockquote>
<p><em>Generate a deterministic ID from text</em></p>
<div id="cell-20" class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>eval_id <span class="op">=</span> generate_id( <span class="st">"aaa"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>({eval_id})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L144" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="force_delete_directory" class="level3">
<h3 class="anchored" data-anchor-id="force_delete_directory">force_delete_directory</h3>
<blockquote class="blockquote">
<pre><code> force_delete_directory (path, max_retries=3, delay=1)</code></pre>
</blockquote>
<p><em>Robust directory deletion with retries and delay</em></p>
<div id="cell-22" class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>force_delete_directory(LANCE_DB_PATH)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We start prefilling our vector database with the metadata</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L171" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="initialise_knowledge_base" class="level3">
<h3 class="anchored" data-anchor-id="initialise_knowledge_base">initialise_knowledge_base</h3>
<blockquote class="blockquote">
<pre><code> initialise_knowledge_base (db, evaluation:Dict)</code></pre>
</blockquote>
<p><em>Store full documents without chunking (late chunking approach)</em></p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L164" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="safe_get" class="level3">
<h3 class="anchored" data-anchor-id="safe_get">safe_get</h3>
<blockquote class="blockquote">
<pre><code> safe_get (d, key, default=None)</code></pre>
</blockquote>
<p><em>Safely get value from dict, handle NaN and missing keys</em></p>
<div id="cell-26" class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>LANCE_DB_PATH <span class="op">=</span> <span class="st">"./lancedb"</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> evaluation <span class="kw">in</span> evaluation_data:  <span class="co"># Assuming evaluation_data is a list</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    initialise_knowledge_base(db, evaluation)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s check each evaluation is in the DB -</p>
<div id="cell-28" class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>eval_table <span class="op">=</span> db.open_table(<span class="st">"evaluations"</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  Convert to Pandas DataFrame (recommended for display)</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> eval_table.to_pandas()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and the corresponding documents…</p>
<div id="cell-30" class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>LANCE_DB_PATH <span class="op">=</span> <span class="st">"./lancedb"</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lancedb <span class="im">import</span> <span class="ex">connect</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>doc_table <span class="op">=</span> db.open_table(<span class="st">"documents"</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  Convert to Pandas DataFrame (recommended for display)</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> doc_table.to_pandas()</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># this table includes document_id, url, and evaluation_id</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="download-and-prepare-all-the-files" class="level3">
<h3 class="anchored" data-anchor-id="download-and-prepare-all-the-files">Download and prepare all the files</h3>
<p>Now we build a smart function to download the files from URL: - this function takes an argument the <code>doc_table</code> from the vector DB (<code>doc_table = db.open_table("documents")</code>). this table includes document_id, url, and evaluation_id - then for each document, and in parallelised way, it loads the url and extract the <code>file_name</code> from the <code>url</code> within the table - it builds a local <code>file_path</code> with <code>PDF_Library</code>/<code>evaluation_id</code>/<code>file_name</code> (where <code>PDF_Library</code> is an environment variable) - it checks if the ‘file_name’ is already present and then gracefully exit - if not, it downloads the file_name - this done with with some provision to avoid requesting IP being banned - and ensure some retry until the file is downloaded - if the file_name extension is not pdf, it identify the file extension then it converts it to pdf</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L332" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="download_documents" class="level3">
<h3 class="anchored" data-anchor-id="download_documents">download_documents</h3>
<blockquote class="blockquote">
<pre><code> download_documents (doc_table)</code></pre>
</blockquote>
<p>Here is the file conversion functions that assumes that <a href="https://www.libreoffice.org/download/download-libreoffice/">libre-office</a> is installed locally.</p>
<pre class="{bash}"><code># Debian/Ubuntu
sudo apt install libreoffice

# Mac (Homebrew)
brew install --cask libreoffice</code></pre>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L449" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="convert_file_to_pdf" class="level3">
<h3 class="anchored" data-anchor-id="convert_file_to_pdf">convert_file_to_pdf</h3>
<blockquote class="blockquote">
<pre><code> convert_file_to_pdf (input_path, output_path)</code></pre>
</blockquote>
<p><em>Converts Word, Excel, or PowerPoint file to PDF using LibreOffice in headless mode. Works on Windows, macOS, and Linux.</em></p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L413" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="find_libreoffice_exec" class="level3">
<h3 class="anchored" data-anchor-id="find_libreoffice_exec">find_libreoffice_exec</h3>
<blockquote class="blockquote">
<pre><code> find_libreoffice_exec ()</code></pre>
</blockquote>
<p><em>Finds the appropriate LibreOffice command based on OS. Returns path to LibreOffice CLI tool or raises an error.</em></p>
<p>Testing this…</p>
<div id="cell-37" class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>doc_table <span class="op">=</span> db.open_table(<span class="st">"documents"</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">"PDF_Library"</span>] <span class="op">=</span> <span class="st">"Evaluation_Library"</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>download_documents(doc_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="now-load-file-content-in-the-vector-db-chunk-and-embedd" class="level3">
<h3 class="anchored" data-anchor-id="now-load-file-content-in-the-vector-db-chunk-and-embedd">Now load file content in the vector DB, chunk and embedd</h3>
<p>Building a function that - this function takes an argument the <code>doc_table</code> from the vector DB (<code>doc_table = db.open_table("documents")</code>). this table includes document_id, url, and evaluation_id, processed - then for each document, and in parallelised way, it loads the url and extract the <code>file_name</code> from the <code>url</code> within the table - it assume a local <code>file_path</code> with <code>PDF_Library</code>/<code>evaluation_id</code>/<code>file_name</code> (where <code>PDF_Library</code> is an environment variable - <code>file_name</code> is extracted from the url - and the <code>file_name</code> extension is sanitised to include systematically ‘.pdf’ ) - It will extract the text from the PDF using PyMuPDF with error handling – it will implement the It will then fill in the chunk table in lancedb, implementing a late chunking approach to avoid duplicate embedding computation, ensure context-aware chunk boundaries and precise span tracking . - the lancedb chunk table schema should be - chunk_id: str - document_id: str - evaluation_id: str - metadata: dict[str, str] - content: str = embedding_fn.SourceField() - vector: Vector(embedding_fn.ndims()) = embedding_fn.VectorField() - Once processed the processed variable in doc_table is set to true</p>
<p>Test the embeddings through lanchain….</p>
<div id="cell-39" class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>test_embedding <span class="op">=</span> embedding_model.embed_query(<span class="st">"Hello world"</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Embedding vector length: </span><span class="sc">{</span><span class="bu">len</span>(test_embedding)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>embedding_dim <span class="op">=</span> <span class="bu">len</span>(test_embedding)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># LanceDB-compatible wrapper</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LangchainEmbeddingWrapper:</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, langchain_embedder):</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._embedder <span class="op">=</span> langchain_embedder</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, texts):</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._embedder.embed_documents(texts)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ndims(<span class="va">self</span>):</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._dim</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Wrap and use</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>embedding_fn <span class="op">=</span> LangchainEmbeddingWrapper(embedding_model)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co">#print("Embedding dimension:", embedding_fn.ndims())</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> embedding_fn([<span class="st">"Hello world"</span>])</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Vector through lancedb dim: </span><span class="sc">{</span><span class="bu">len</span>(vec[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(embedding_fn([<span class="st">"Hello world"</span>])[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-40" class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">dir</span>(embedding_fn))</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(embedding_fn)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So first we create the chunk table in lancedb</p>
<div id="cell-42" class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lancedb.pydantic <span class="im">import</span> Vector</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow <span class="im">as</span> pa </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>pa_schema <span class="op">=</span> pa.schema([</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"chunk_id"</span>, pa.string()),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"document_id"</span>, pa.string()),</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"evaluation_id"</span>, pa.string()),</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"metadata"</span>, pa.string()),  <span class="co"># storing metadata dict as JSON string for simplicity</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"content"</span>, pa.string()),</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    pa.field(<span class="st">"vector"</span>, pa.list_(pa.float32(), embedding_dim)),  <span class="co"># vector as list of floats</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lancedb <span class="im">import</span> <span class="ex">connect</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>chunk_table <span class="op">=</span> db.create_table(<span class="st">"chunks"</span>, schema<span class="op">=</span>pa_schema)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>and then the function creating embeddings chunck for each document</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L543" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="process_documents_to_chunks" class="level3">
<h3 class="anchored" data-anchor-id="process_documents_to_chunks">process_documents_to_chunks</h3>
<blockquote class="blockquote">
<pre><code> process_documents_to_chunks (doc_table, chunk_table)</code></pre>
</blockquote>
<p>Now let’s run this!</p>
<div id="cell-46" class="cell">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>LANCE_DB_PATH <span class="op">=</span> <span class="st">"./lancedb"</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lancedb <span class="im">import</span> <span class="ex">connect</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>doc_table <span class="op">=</span> db.open_table(<span class="st">"documents"</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>chunk_table <span class="op">=</span> db.open_table(<span class="st">"chunks"</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>process_documents_to_chunks(doc_table, chunk_table)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Checking the status of the chunking process</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L681" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="check_chunk_status" class="level3">
<h3 class="anchored" data-anchor-id="check_chunk_status">check_chunk_status</h3>
<blockquote class="blockquote">
<pre><code> check_chunk_status (doc_table, chunk_table)</code></pre>
</blockquote>
<div id="cell-49" class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>LANCE_DB_PATH <span class="op">=</span> <span class="st">"./lancedb"</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lancedb <span class="im">import</span> <span class="ex">connect</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>doc_table <span class="op">=</span> db.open_table(<span class="st">"documents"</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>chunk_table <span class="op">=</span> db.open_table(<span class="st">"chunks"</span>)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>missing_docs_df <span class="op">=</span> check_chunk_status(doc_table, chunk_table)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_docs_df)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># this table includes document_id, url, and evaluation_id</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="generating-ai-enhanced-metadata" class="level3">
<h3 class="anchored" data-anchor-id="generating-ai-enhanced-metadata">Generating AI-Enhanced metadata</h3>
<p>Last, we run a function to generate metadata…</p>
<p>The function will load the “evaluations” table within the db –connect(LANCE_DB_PATH) – then loop around each evaluation_id within the “chunks” table to retrive the context - and perform an LLM call to then generate as an output additional metadata Then it will update the evaluations table with the output for each evaluation - At the end it will save a json file with a dump of the evaluations table</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L840" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="get_context_for_eval" class="level3">
<h3 class="anchored" data-anchor-id="get_context_for_eval">get_context_for_eval</h3>
<blockquote class="blockquote">
<pre><code> get_context_for_eval (eval_row, query, chunk_table)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L798" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="call_llm_with_retries" class="level3">
<h3 class="anchored" data-anchor-id="call_llm_with_retries">call_llm_with_retries</h3>
<blockquote class="blockquote">
<pre><code> call_llm_with_retries (prompt, max_retries=4, delay=2)</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L786" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="safe_join" class="level3">
<h3 class="anchored" data-anchor-id="safe_join">safe_join</h3>
<blockquote class="blockquote">
<pre><code> safe_join (items, sep=', ')</code></pre>
</blockquote>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L761" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="clean_json" class="level3">
<h3 class="anchored" data-anchor-id="clean_json">clean_json</h3>
<blockquote class="blockquote">
<pre><code> clean_json (obj)</code></pre>
</blockquote>
<p><em>Recursively clean an object to make it JSON serializable, handling None values.</em></p>
<p>We will use the <strong>PICO structured framework</strong> as an approach to represent the causal knowledge found in the Evaluation (cf.&nbsp;<a href="https://aclanthology.org/2023.findings-emnlp.774.pdf">EconBERTa: Towards Robust Extraction of Named Entities in Economics</a>). This scheme helps in systematically organizing and analyzing the effectiveness of interventions by comparing outcomes between groups:</p>
<p><strong>1. Population (P)</strong>: The group of individuals or units (e.g., households, schools, firms) affected by the intervention. The target population shall be clearly defined (e.g., smallholder farmers, primary school students, unemployed youth) and it shall Include eligibility criteria (e.g., age, socioeconomic status, geographic location).</p>
<p><strong>2. Intervention (I)</strong>: The program, policy, or treatment whose effect is being evaluated. Describes the active component being tested (e.g., cash transfers, training workshops, new teaching methods). Should specify dosage, duration, and delivery mechanism.</p>
<p><strong>3. Comparators (C)</strong>: The counterfactual scenario—what would have happened without the intervention. Ideally involves a control group (if the study approach is randomized or quasi-experimental) that does not receive the intervention. Alternatively refers to “Business-as-usual” groups, placebo interventions, or different treatment arms.</p>
<p><strong>4. Outcome (O)</strong>:The measurable effects or endpoints used to assess the intervention’s impact. Includes primary outcomes (main indicators of interest, e.g., school enrollment rates, income levels) and secondary outcomes (e.g., health, empowerment). Should be specific, measurable, and time-bound (e.g., “child literacy scores after 12 months”).</p>
<p>Using such approach, we can ensure Clarity (the research question is well-defined and testable), Causal Inference (isolate the effect of the intervention by comparing treated and untreated groups), Replicability (to potentially extrapolate the findings) and Relevance (linking outcomes to real-world decision-making).</p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L870" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="generate_metadata_for_evaluation_metadata_descriptive" class="level3">
<h3 class="anchored" data-anchor-id="generate_metadata_for_evaluation_metadata_descriptive">generate_metadata_for_evaluation_metadata_descriptive</h3>
<blockquote class="blockquote">
<pre><code> generate_metadata_for_evaluation_metadata_descriptive (eval_row,
                                                        query_descriptive,
                                                        chunk_table)</code></pre>
</blockquote>
<p><em>Process one evaluation row and return updated row with metadata.</em></p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L948" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="generate_metadata_for_evaluation_metadata_methodo" class="level3">
<h3 class="anchored" data-anchor-id="generate_metadata_for_evaluation_metadata_methodo">generate_metadata_for_evaluation_metadata_methodo</h3>
<blockquote class="blockquote">
<pre><code> generate_metadata_for_evaluation_metadata_methodo (eval_row,
                                                    query_methodo,
                                                    chunk_table)</code></pre>
</blockquote>
<p><em>Process one evaluation row and return updated row with metadata.</em></p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L1045" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="generate_metadata_for_evaluation_metadata_evidence" class="level3">
<h3 class="anchored" data-anchor-id="generate_metadata_for_evaluation_metadata_evidence">generate_metadata_for_evaluation_metadata_evidence</h3>
<blockquote class="blockquote">
<pre><code> generate_metadata_for_evaluation_metadata_evidence (eval_row, query,
                                                     chunk_table)</code></pre>
</blockquote>
<p><em>Process one evaluation row and return updated row with metadata.</em></p>
<hr>
<p><a href="https://github.com/iom/evaluation_knowledge/blob/main/evaluation_knowledge/core.py#L1119" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="generate_evaluation_metadata" class="level3">
<h3 class="anchored" data-anchor-id="generate_evaluation_metadata">generate_evaluation_metadata</h3>
<blockquote class="blockquote">
<pre><code> generate_evaluation_metadata (eval_table, chunk_table, batch_size=10,
                               output_file='all_evaluations_metadata.json'
                               )</code></pre>
</blockquote>
<p><em>Main function to generate metadata in batches and update the table, with incremental saving.</em></p>
<p>Now let’s run it!</p>
<div id="cell-61" class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize DB</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>LANCE_DB_PATH <span class="op">=</span> <span class="st">"./lancedb"</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>db <span class="op">=</span> <span class="ex">connect</span>(LANCE_DB_PATH)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>eval_table <span class="op">=</span> db.open_table(<span class="st">"evaluations"</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>chunk_table <span class="op">=</span> db.open_table(<span class="st">"chunks"</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>enriched_data<span class="op">=</span> generate_evaluation_metadata(eval_table, chunk_table, output_file<span class="op">=</span><span class="st">"all_evaluations_metadata2.json"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="step-2-structured-information-extraction" class="level2">
<h2 class="anchored" data-anchor-id="step-2-structured-information-extraction">Step 2: Structured Information Extraction</h2>
<section id="standard-questions" class="level3">
<h3 class="anchored" data-anchor-id="standard-questions">Standard Questions</h3>
<pre class="{python}"><code># Define the list of experts on impact - outcome - organisation
q_experts = [
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the Strategic Impact: ---Attaining favorable protection environments---: i.e., finding or recommendations that require a change in existing policy and regulations. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the Strategic Impact: ---Realizing rights in safe environments---: i.e., finding or recommendations that require a change in existing policy and regulations. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the Strategic Impact: ---Empowering communities and achieving gender equality--- : i.e., finding or recommendations that require a change in existing policy and regulations. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the Strategic Impact: ---Securing durable solutions--- : i.e., finding or recommendations that require a change in existing policy and regulations. [/INST]",

   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: ---Access to territory registration and documentation ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Status determination ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Protection policy and law---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Gender-based violence ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Child protection ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Safety and access to justice ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Community engagement and women's empowerment ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Well-being and basic needs ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Sustainable housing and settlements ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Healthy lives---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Education ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Clean water sanitation and hygiene ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Self-reliance, Economic inclusion, and livelihoods ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Voluntary repatriation and sustainable reintegration ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Resettlement and complementary pathways---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on the specific Operational Outcome: --- Local integration and other local solutions ---, i.e. finding or recommendations that require a change that needs to be implemented in the field as an adaptation or change of current activities. [/INST]", 


   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on Organizational Enablers related to Systems and processes, i.e. elements that require potential changes in either management practices, technical approach, business processes, staffing allocation or capacity building. [/INST]",
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on Organizational Enablers related to Operational support and supply chain, i.e. elements that require potential changes in either management practices, technical approach, business processes, staffing allocation or capacity building. [/INST]" ,
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on Organizational Enablers related to People and culture, i.e. elements that require potential changes in either management practices, technical approach, business processes, staffing allocation or capacity building. [/INST]" ,
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on Organizational Enablers related to External engagement and resource mobilization, i.e. elements that require potential changes in either management practices, technical approach, business processes, staffing allocation or capacity building. [/INST]" ,
   "&lt;s&gt; [INST] Instructions: Act as a public program evaluation expert working for UNHCR. Your specific area of expertise and focus is strictly on Organizational Enablers related to Leadership and governance, i.e. elements that require potential changes in either management practices, technical approach, business processes, staffing allocation or capacity building. [/INST]" 
]

# Predefined knowledge extraction questions
q_questions = [
    " List, as bullet points, all findings and evidences in relation to your specific area of expertise and focus. ",
    " Explain, in relation to your specific area of expertise and focus, what are the root causes for the situation. " ,
    " Explain, in relation to your specific area of expertise and focus, what are the main risks and difficulties here described. ",
    " Explain, in relation to your specific area of expertise and focus, what what can be learnt. ",
    " List, as bullet points, all recommendations made in relation to your specific area of expertise and focus. "#,
    # "Indicate if mentionnend what resource will be required to implement the recommendations made in relation to your specific area of expertise and focus. ",
    # "List, as bullet points, all recommendations made in relation to your specific area of expertise and focus that relates to topics  or activities recommended to be discontinued. ",
    # "List, as bullet points, all recommendations made in relation to your specific area of expertise and focus that relates to topics or activities recommended to be scaled up. " 
    # Add more questions here...
]

## Additional instructions!
q_instr = """
&lt;/s&gt;
[INST]  
Keep your answer grounded in the facts of the contexts. 
If the contexts do not contain the facts to answer the QUESTION, return {NONE} 
Be concise in the response and  when relevant include precise citations from the contexts. 
[/INST] 
"""</code></pre>
</section>
<section id="qa-extraction" class="level3">
<h3 class="anchored" data-anchor-id="qa-extraction">Q&amp;A Extraction</h3>
<pre class="{python}"><code>qa_questions = [
    "What was the intervention type?",
    "What outcomes were observed?",
    "What population was targeted?",
    "What geographic area was covered?",
    "How strong is the evidence?",
]

def generate_qas(text):
    prompt = f"""Extract answers to the following questions from the evaluation:
    {json.dumps(qa_questions)}
    
    Text: {text[:3000]}
    """
    completion = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2
    )
    return completion.choices[0].message.content

df_docs["qa"] = df_docs["text"].apply(generate_qas)</code></pre>
</section>
<section id="hybrid-search-in-lancedb" class="level3">
<h3 class="anchored" data-anchor-id="hybrid-search-in-lancedb">Hybrid Search in LanceDB</h3>
<pre class="{python}"><code># Sample hybrid search query
query = "What works best to improve health outcomes for displaced persons?"

query_embedding = get_text_embedding(query)
results = table.search(query_embedding).limit(5).to_list()

for result in results:
    print(result['metadata'])
    print(result['text'][:500])</code></pre>
<pre class="{python}"><code>def query_evidence(question: str, table: lancedb.db.LanceTable) -&gt; Dict:
    """Enhanced query with hybrid search and evidence grading"""
    try:
        # Hybrid search
        results = hybrid_search(table, question, limit=7)
        
        if results.empty:
            return {"answer": "No relevant evidence found.", "sources": []}
        
        context = "\n\n".join([
            f"Document {i+1} (Relevance: {row.get('combined_score', 0):.2f}):\n{row['text']}\n"
            for i, row in results.iterrows()
        ])
        
        # Evidence-based answer generation
        prompt = f"""
        You are an evidence specialist answering questions about IOM programs.
        Use ONLY the provided context from evaluation reports.
        For each claim in your answer, cite the document number it came from.
        
        Question: {question}
        
        Context:
        {context}
        
        Provide:
        1. A direct answer to the question
        2. Strength of evidence (High/Medium/Low)
        3. Any limitations or caveats
        4. List of sources with relevance scores
        """
        
        response = openai.ChatCompletion.create(
            engine=config.chat_model,
            messages=[{"role": "user", "content": prompt}],
            temperature=config.temperature,
            max_tokens=config.max_tokens
        )
        
        answer = response.choices[0].message.content
        sources = [
            {"url": url, "score": score}
            for url, score in zip(results['url'], results.get('combined_score', 0))
        ]
        
        return {
            "question": question,
            "answer": answer,
            "sources": sources,
            "search_scores": results[['_distance', '_score', 'combined_score']].to_dict()
        }
    
    except Exception as e:
        print(f"Query error: {str(e)}")
        return {"error": str(e)}
</code></pre>
<pre class="{python}"><code>def extract_structured_info(table, iom_framework):
    """Extract structured information from reports using the IOM Results Framework"""
    # Generate questions based on the IOM framework
    questions = generate_questions_from_framework(iom_framework)
    
    # Store extracted information
    extracted_data = []
    
    # Process each question
    for question in questions:
        print(f"Processing question: {question}")
        
        # Search for relevant chunks
        results = table.search(generate_embeddings([question])[0]).limit(10).to_pandas()
        
        # Combine relevant chunks as context
        context = "\n\n".join(results["text"].tolist())
        
        # Use Azure OpenAI to extract structured answer
        prompt = f"""
        Based on the following evaluation report excerpts, answer the question with structured information.
        Provide your answer in JSON format with the following structure:
        {{
            "question": "the question being asked",
            "answer": "the concise answer",
            "intervention_type": "type of intervention mentioned",
            "population": "target population mentioned",
            "outcome": "outcome measured",
            "geography": "geographic location if mentioned",
            "evidence_strength": "strength of evidence (high/medium/low)"
        }}

        Question: {question}
        Context: {context}
        """
        
        response = openai.ChatCompletion.create(
            engine=config["azure_openai_chat_deployment"],
            messages=[{"role": "user", "content": prompt}],
            temperature=config["temperature"],
            max_tokens=config["max_tokens"]
        )
        
        try:
            answer = json.loads(response.choices[0].message.content)
            answer["source_urls"] = results["url"].unique().tolist()
            extracted_data.append(answer)
        except json.JSONDecodeError:
            print(f"Failed to parse answer for question: {question}")
    
    return pd.DataFrame(extracted_data)

def generate_questions_from_framework(framework_df):
    """Generate questions based on the IOM Results Framework"""
    questions = []
    
    # Example questions based on common evaluation themes
    for _, row in framework_df.iterrows():
        questions.extend([
            f"What interventions has IOM implemented to achieve {row['Objective']}?",
            f"What evidence exists for the effectiveness of interventions targeting {row['Outcome']}?",
            f"What populations have been targeted by interventions aiming for {row['Indicator']}?",
            f"What geographic areas have seen interventions related to {row['Objective']}?",
            f"What methodologies have been used to evaluate interventions for {row['Outcome']}?"
        ])
    
    # Add some general evaluation questions
    questions.extend([
        "What are the most effective interventions for migrant livelihood improvement?",
        "What evidence exists for cash-based interventions in migration contexts?",
        "What are common challenges in implementing migration programs?",
        "What evaluation methodologies are most commonly used in IOM evaluations?",
        "What gaps exist in the evidence base for migration interventions?"
    ])
    
    return list(set(questions))  # Remove duplicates

def hybrid_search(table: lancedb.db.LanceTable, query: str, limit: int = 10) -&gt; pd.DataFrame:
    """Perform hybrid (vector + full-text) search"""
    # Generate query embedding
    query_embedding = generate_embeddings_batch([query])[0]
    
    # Perform hybrid search
    results = table.search(query_embedding, query_string=query)\
                 .limit(limit)\
                 .to_pandas()
    
    # Score normalization (simple example)
    if not results.empty:
        max_vector_score = results["_distance"].max()
        max_fts_score = results["_score"].max()
        
        if max_vector_score &gt; 0 and max_fts_score &gt; 0:
            results["combined_score"] = (
                0.7 * (results["_distance"] / max_vector_score) +
                0.3 * (results["_score"] / max_fts_score)
            )
            results = results.sort_values("combined_score", ascending=False)
    
    return results

def extract_structured_info(table: lancedb.db.LanceTable, iom_framework: pd.DataFrame) -&gt; pd.DataFrame:
    """Enhanced information extraction with hybrid search"""
    questions = generate_questions_from_framework(iom_framework)
    extracted_data = []
    
    for question in questions:
        try:
            # Hybrid search for relevant chunks
            results = hybrid_search(table, question, limit=15)
            
            if results.empty:
                continue
                
            context = "\n\n".join(results["text"].tolist())
            sources = results["url"].unique().tolist()
            
            # Structured extraction prompt
            prompt = f"""
            Extract structured information from this evaluation report context to answer the question.
            Return ONLY valid JSON with this structure:
            {{
                "question": "the question",
                "answer": "concise answer",
                "intervention_type": ["type1", "type2"],
                "population": ["group1", "group2"],
                "outcome": ["outcome1", "outcome2"],
                "geography": ["location1", "location2"],
                "evidence_strength": "high/medium/low",
                "source_urls": ["url1", "url2"]
            }}
            
            Question: {question}
            Context: {context}
            """
            
            response = openai.ChatCompletion.create(
                engine=config.chat_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=config.temperature,
                max_tokens=config.max_tokens,
                response_format={ "type": "json_object" }
            )
            
            answer = json.loads(response.choices[0].message.content)
            answer["source_urls"] = sources
            extracted_data.append(answer)
            
        except Exception as e:
            print(f"Error processing question '{question}': {str(e)}")
            continue
    
    return pd.DataFrame(extracted_data)
</code></pre>
</section>
</section>
<section id="step-3-cross-evaluation-analysis" class="level2">
<h2 class="anchored" data-anchor-id="step-3-cross-evaluation-analysis">Step 3: Cross-Evaluation Analysis</h2>
</section>
<section id="step-4-generate-actionable-and-generalizable-insights" class="level2">
<h2 class="anchored" data-anchor-id="step-4-generate-actionable-and-generalizable-insights">Step 4: Generate Actionable and Generalizable Insights</h2>
<p>One key challenge is How to generalize the findings from an evaluation from one place to another one? The <a href="https://ssir.org/articles/entry/the_generalizability_puzzle">Generalizability Framework</a> provides some insights on how to do that.</p>
<p>To implement this we will generate insights using AI-enabled Q&amp;A on all previous Q&amp;A:</p>
<pre class="{python}"><code>def generate_insights(df):
    # Add your insight generation logic here
    return df

df = generate_insights(df)</code></pre>
</section>
<section id="step-5-identify-patterns-and-gaps" class="level2">
<h2 class="anchored" data-anchor-id="step-5-identify-patterns-and-gaps">Step 5: Identify Patterns and Gaps</h2>
<p>Identify patterns and gaps in the data:</p>
<pre class="{python}"><code>def identify_patterns(df):
    # Add your pattern identification logic here
    return df

df = identify_patterns(df)</code></pre>
<pre class="{python}"><code>def generate_deliverables(df):
    # Generate Q&amp;A dataset
    qa_dataset = df[['question', 'answer']]

    # Generate synthesis report
    synthesis_report = df.describe()

    # Generate visual evidence map
    plt.figure(figsize=(10, 6))
    sns.scatterplot(data=df, x='outcome', y='population', size='sample_size')
    plt.title('Visual Evidence Map')
    plt.show()

    return qa_dataset, synthesis_report

qa_dataset, synthesis_report = generate_deliverables(df)</code></pre>
<p>Visualize Patterns &amp; Gaps</p>
<pre class="{python}"><code># Convert QA to structured fields (intervention, outcome, population, etc.)
qa_df = pd.json_normalize(df_docs["qa"].apply(json.loads))

# Bubble Map Example
fig = px.scatter(qa_df, x="geography", y="outcome",
                 size="sample_size", color="intervention",
                 hover_name="file_name",
                 title="Evidence Bubble Map")
fig.show()

# Heatmap Example
heatmap_df = pd.crosstab(qa_df["intervention"], qa_df["outcome"])
sns.heatmap(heatmap_df, annot=True, cmap="coolwarm")</code></pre>
<pre class="{python}"><code>def create_interactive_visualizations(extracted_data: pd.DataFrame):
    """Enhanced visualization functions"""
    # Prepare data
    df = extracted_data.explode("source_urls")
    
    # Evidence Strength Distribution
    strength_dist = df['evidence_strength'].value_counts().reset_index()
    fig1 = px.bar(
        strength_dist,
        x='evidence_strength',
        y='count',
        title='Distribution of Evidence Strength'
    )
    
    # Interventions by Geography
    fig2 = px.treemap(
        df,
        path=['geography', 'intervention_type'],
        title='Interventions by Geographic Region'
    )
    
    # Evidence Timeline (if dates available)
    if 'date' in df.columns:
        fig3 = px.line(
            df.groupby('date').size().reset_index(name='count'),
            x='date',
            y='count',
            title='Evidence Publication Timeline'
        )
    else:
        fig3 = None
    
    return fig1, fig2, fig3
</code></pre>
<pre class="{python}"><code>def visualize_evidence_map(extracted_data):
    """Create interactive visualizations of the evidence map"""
    
    # Prepare data for visualization
    df = extracted_data.explode("source_urls")
    
    # Bubble map: Interventions by outcome and evidence strength
    fig1 = px.scatter(
        df, 
        x="outcome", 
        y="intervention_type", 
        size="evidence_strength",  # This would need to be mapped to numeric values
        color="population",
        hover_name="answer",
        title="Evidence Map: Interventions by Outcome and Population"
    )
    fig1.update_layout(height=800)
    
    # Heatmap: Evidence concentration by intervention and outcome
    heatmap_data = df.groupby(['intervention_type', 'outcome']).size().unstack().fillna(0)
    fig2 = px.imshow(
        heatmap_data,
        labels=dict(x="Outcome", y="Intervention Type", color="Number of Studies"),
        title="Evidence Concentration Heatmap"
    )
    
    # Gap map: Missing evidence
    all_interventions = df['intervention_type'].unique()
    all_outcomes = df['outcome'].unique()
    complete_grid = pd.MultiIndex.from_product([all_interventions, all_outcomes], names=['intervention_type', 'outcome'])
    gap_data = df.groupby(['intervention_type', 'outcome']).size().reindex(complete_grid, fill_value=0).reset_index()
    gap_data['has_evidence'] = gap_data[0] &gt; 0
    
    fig3 = px.scatter(
        gap_data,
        x="outcome",
        y="intervention_type",
        color="has_evidence",
        title="Evidence Gap Map (Red = Missing Evidence)"
    )
    
    return fig1, fig2, fig3

def generate_synthesis_report(extracted_data):
    """Generate a narrative synthesis report of findings"""
    prompt = f"""
    You are an evaluation specialist analyzing evidence from IOM evaluation reports.
    Below is structured data extracted from multiple evaluation reports:
    
    {extracted_data.to_json()}
    
    Write a comprehensive synthesis report that:
    1. Summarizes key findings across interventions
    2. Identifies areas with strong evidence
    3. Highlights evidence gaps
    4. Provides recommendations for future evaluations
    5. Suggests high-priority research areas
    
    Structure your report with clear sections and bullet points for readability.
    """
    
    response = openai.ChatCompletion.create(
        engine=config["azure_openai_chat_deployment"],
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,  # Slightly more creative for synthesis
        max_tokens=3000
    )
    
    return response.choices[0].message.content
</code></pre>
<p>Save the deliverables to files:</p>
<pre class="{python}"><code>qa_dataset.to_csv('qa_dataset.csv', index=False)
synthesis_report.to_csv('synthesis_report.csv')</code></pre>
</section>
<section id="conclusions---and-potential-extension" class="level2">
<h2 class="anchored" data-anchor-id="conclusions---and-potential-extension">Conclusions - and potential extension…</h2>
<ul>
<li><p>Web interface (Streamlit, Gradio, etc.)</p></li>
<li><p>Periodic syncing with new evaluations via web scraping</p></li>
<li><p>Integration with Hugging Face for fine-tuning a summarization or Q&amp;A model</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/iom\.github\.io\/evaluation_knowledge");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/iom/evaluation_knowledge/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>