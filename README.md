# Evaluation Evidence Mapping  

## Introduction

An **Evaluation Evidence Map** is a visual and systematic way to organize what we know (and don't know) about programs, policies, or interventions. Think of it as creating a "research landscape" that helps decision-makers quickly see:

- What interventions have been studied
- Where they've been implemented
- What results were found
- Where important gaps exist

This approach is particularly valuable when designing projects that need to make evidence-based decisions but when project designer don't have time to read hundreds of reports.

## Non-Technical Approach

### Step 1: Define Focus
**Ask yourself:**
- What types of programs/interventions are we interested in? (e.g., [IOM strategic Results Framework](https://www.iom.int/sites/g/files/tmzbdl486/files/our_work/ICP/IOM-Strategic-Results-Framework.pdf))
- What populations are we focusing on? (e.g., migrants, host communities)
- What outcomes matter most? (e.g., test scores, disease rates)
- Who is the audience for this map? (policymakers, researchers, funders, project managers)
- What are the key questions we want to answer? (e.g., "What works best for improving educational outcomes in rural areas?")
- What is the time frame for our mapping? (e.g., last 5 years, all time)    
- What is the geographic scope? (e.g., global, regional, country-specific)
- What is the level of evidence we need? (e.g., randomized controlled trials, observational studies)
- What are the key variables we want to track? (e.g., program type, target population, outcome measures)    
 

### Step 2: Building the Knowledge Base

We have set up a list with the URL of all the evaluation reports published by IOM.


### Step 3: Extract Key Information
We'll use AI tools to help us extract key information from the reports. This will save time and ensure consistency across studies.

- **What** was implemented (the program details)
- **Where** and **with whom** it was tested
- **How** it was studied (study design)
- **What** results were found
- **How confident** we are in the findings

### Step 4: Organize the Evidence

We'll categorize studies into a consistent framework:
1. By **program type** (e.g., tutoring, mentoring, vocational training)
2. By **outcome measured** (e.g., math scores, graduation rates)
3. By **population** (e.g., elementary students, rural communities)
4. By **study quality** (gold-standard studies vs. preliminary research)

### Step 5: Identify Patterns and Gaps

The system will help us spot:
✅ Areas with lots of consistent evidence  
⚠️ Areas with conflicting results  
❌ Important questions no one has studied  

*Example finding:* "We have strong evidence that mentoring programs work for urban youth, but almost no studies on rural populations."

### Step 6: Create Visual Maps

We'll generate easy-to-understand charts showing:
- **Bubble maps** (where bubble size = study size)
- **Heatmaps** (showing evidence density)
- **Gap maps** (highlighting unstudied areas)

### Step 7: Generate Actionable Insights through AI-ready Q&A

The system will produce plain-language summaries answering:
- "What works best for [X goal] in [Y context]?"

### Step 8: Share Findings

We'll create a final report for:
- "Where should we focus future research?"
- "Which programs are riskiest to implement?"


